name: Tree-Based Architecture CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - 'CHANGELOG.md'
  pull_request:
    branches: [ main, develop ]
    paths-ignore:
      - 'docs/**'
      - '*.md'
      - 'CHANGELOG.md'
  workflow_dispatch:
    inputs:
      run_performance_tests:
        description: 'Run tree-based performance tests'
        required: false
        default: 'true'
        type: boolean
      run_javascript_tests:
        description: 'Run JavaScript client tests'
        required: false  
        default: 'true'
        type: boolean

env:
  GO_VERSION: '1.23'
  NODE_VERSION: '20'

jobs:
  # Code quality and unit tests
  quality-gate:
    name: Code Quality Gate
    runs-on: ubuntu-latest
    outputs:
      cache-key: ${{ steps.cache-key.outputs.key }}
      
    steps:
    - name: Check out code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Generate cache key
      id: cache-key
      run: echo "key=${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}-${{ github.sha }}" >> $GITHUB_OUTPUT

    - name: Install dependencies
      run: go mod download

    - name: Run CI validation  
      run: |
        chmod +x ./scripts/ci.sh
        ./scripts/ci.sh --mode=fast

    - name: Generate coverage report  
      run: |
        go test -coverprofile=coverage.out -covermode=atomic ./...
        go tool cover -html=coverage.out -o coverage.html

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.out
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

    - name: Upload quality artifacts
      uses: actions/upload-artifact@v3
      with:
        name: quality-reports
        path: |
          coverage.out
          coverage.html
        retention-days: 7

  # Cross-platform build verification
  build-verification:
    name: Build Verification (${{ matrix.os }})
    needs: quality-gate
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        
    steps:
    - name: Check out code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Build application
      run: go build -v ./...

    - name: Run unit tests
      run: go test -short -v ./...

  # JavaScript client tests
  javascript-tests:
    name: JavaScript Client Tests
    needs: [quality-gate, build-verification]
    runs-on: ubuntu-latest
    if: github.event.inputs.run_javascript_tests == 'true' || github.event_name != 'workflow_dispatch'
    
    timeout-minutes: 15

    steps:
    - name: Check out code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Test JavaScript client
      run: |
        # Validate JavaScript syntax
        node -c pkg/client/web/tree-fragment-client.js
        echo "✅ JavaScript client syntax is valid"

    - name: Test example demos
      run: |
        # Test tree-based examples compile and run
        timeout 5s go run examples/bandwidth-savings/main.go || echo "Bandwidth demo completed"
        timeout 5s go run examples/template-constructs/main.go || echo "Template constructs demo completed"
        echo "✅ Example demos work correctly"

    - name: Validate tree-based optimization
      run: |
        # Run tree optimization tests specifically 
        go test -v ./internal/strategy/ -run "TreeOptimization"
        echo "✅ Tree-based optimization tests pass"

    - name: Upload JavaScript artifacts
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: javascript-client-artifacts
        path: |
          pkg/client/web/
          examples/javascript/
        retention-days: 7


  # Performance testing
  performance-tests:
    name: Tree-Based Performance Benchmarks
    needs: [quality-gate]
    runs-on: ubuntu-latest
    if: github.event.inputs.run_performance_tests == 'true' || github.event_name != 'workflow_dispatch'
    
    steps:
    - name: Check out code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run tree-based performance benchmarks
      run: |
        mkdir -p perf-artifacts
        # Run tree optimization benchmarks
        go test ./internal/strategy/ -v -bench=. -benchmem -timeout 10m | tee perf-artifacts/tree-benchmarks.txt
        # Run integration benchmarks
        go test ./internal/ -v -bench=. -benchmem -timeout 10m | tee -a perf-artifacts/integration-benchmarks.txt
        # Test bandwidth savings demos
        timeout 10s go run examples/bandwidth-savings/main.go | tee perf-artifacts/bandwidth-demo.txt || true

    - name: Analyze performance results
      run: |
        echo "## Tree-Based Optimization Performance Results" > perf-artifacts/performance-summary.md
        echo "" >> perf-artifacts/performance-summary.md
        echo "### Benchmark Results" >> perf-artifacts/performance-summary.md
        grep -E "(Benchmark|ns/op|B/op)" perf-artifacts/tree-benchmarks.txt >> perf-artifacts/performance-summary.md || true
        echo "" >> perf-artifacts/performance-summary.md
        echo "### Bandwidth Savings" >> perf-artifacts/performance-summary.md
        grep -E "(savings|reduction|bytes)" perf-artifacts/bandwidth-demo.txt >> perf-artifacts/performance-summary.md || true

    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: tree-based-performance-benchmarks
        path: |
          perf-artifacts/
        retention-days: 30

  # Security and vulnerability scanning
  security-scan:
    name: Security Scan
    needs: quality-gate
    runs-on: ubuntu-latest
    
    steps:
    - name: Check out code
      uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v4
      with:
        go-version: ${{ env.GO_VERSION }}
        cache: true

    - name: Run Gosec security scanner
      uses: securecodewarrior/github-action-gosec@master
      with:
        args: './...'

    - name: Run Nancy vulnerability scanner
      run: |
        go list -json -deps ./... | docker run --rm -i sonatypecommunity/nancy:latest sleuth

  # Final reporting and deployment preparation
  final-report:
    name: Final Test Report  
    needs: [javascript-tests, performance-tests, security-scan]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Check out code
      uses: actions/checkout@v4

    - name: Download all artifacts
      uses: actions/download-artifact@v3
      with:
        path: all-artifacts

    - name: Generate comprehensive report
      run: |
        cat > final-report.md << 'EOF'
        # LiveTemplate CI/CD Pipeline Report

        **Commit:** ${{ github.sha }}
        **Branch:** ${{ github.ref_name }}
        **Workflow:** [${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
        **Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")

        ## Pipeline Results

        | Stage | Status | Duration | Artifacts |
        |-------|---------|----------|-----------|
        | Quality Gate | ${{ needs.quality-gate.result == 'success' && '✅' || '❌' }} | - | Coverage Reports |
        | Build Verification | ${{ needs.build-verification.result == 'success' && '✅' || '❌' }} | - | Build Logs |
        | JavaScript Tests | ${{ needs.javascript-tests.result == 'success' && '✅' || needs.javascript-tests.result == 'skipped' && '⏭️' || '❌' }} | - | Client Artifacts |
        | Tree Performance Tests | ${{ needs.performance-tests.result == 'success' && '✅' || needs.performance-tests.result == 'skipped' && '⏭️' || '❌' }} | - | Benchmarks |
        | Security Scan | ${{ needs.security-scan.result == 'success' && '✅' || needs.security-scan.result == 'skipped' && '⏭️' || '❌' }} | - | Security Reports |

        ## Test Coverage

        EOF

        # Add coverage information if available
        if [ -f "all-artifacts/quality-reports/coverage.out" ]; then
          coverage=$(go tool cover -func=all-artifacts/quality-reports/coverage.out | tail -1 | awk '{print $3}')
          echo "**Overall Coverage:** $coverage" >> final-report.md
        fi

        # Add artifact summary
        echo "" >> final-report.md
        echo "## Artifacts Summary" >> final-report.md
        echo "" >> final-report.md
        
        artifact_count=0
        if [ -d "all-artifacts" ]; then
          artifact_count=$(find all-artifacts -type f | wc -l)
        fi
        
        echo "- **Total Artifacts:** $artifact_count files" >> final-report.md
        echo "- **Screenshots Captured:** $(find all-artifacts -name "*.png" 2>/dev/null | wc -l)" >> final-report.md
        echo "- **Test Reports:** $(find all-artifacts -name "*-report.md" 2>/dev/null | wc -l)" >> final-report.md
        echo "- **Performance Data:** $(find all-artifacts -name "*benchmark*" 2>/dev/null | wc -l)" >> final-report.md

        echo "" >> final-report.md
        echo "---" >> final-report.md
        echo "*Generated by LiveTemplate CI/CD Pipeline*" >> final-report.md

        cat final-report.md

    - name: Comment on PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = fs.readFileSync('final-report.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,  
            repo: context.repo.repo,
            body: report
          });

    - name: Upload final report
      uses: actions/upload-artifact@v3
      with:
        name: final-ci-report
        path: |
          final-report.md
        retention-days: 30

    - name: Check overall pipeline status
      run: |
        echo "Quality Gate: ${{ needs.quality-gate.result }}"
        echo "Build Verification: ${{ needs.build-verification.result }}"
        echo "JavaScript Tests: ${{ needs.javascript-tests.result }}"
        echo "Performance: ${{ needs.performance-tests.result }}"
        echo "Security: ${{ needs.security-scan.result }}"

        # Fail if any required job failed
        if [ "${{ needs.quality-gate.result }}" = "failure" ] || \
           [ "${{ needs.build-verification.result }}" = "failure" ] || \
           [ "${{ needs.javascript-tests.result }}" = "failure" ]; then
          echo "❌ Required jobs failed - failing pipeline"
          exit 1
        fi

        # Optional jobs don't fail the pipeline
        echo "✅ All required jobs passed"